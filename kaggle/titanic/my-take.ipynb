{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c672c6",
   "metadata": {},
   "source": [
    "# Kaggle Titanic Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7360efd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea418b6",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('./data/train.csv')\n",
    "# test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78a40fa",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# survival: 0=No, 1=Yes\n",
    "# pclass(Ticket class): 1=1st, 2=2nd, 3=3rd\n",
    "# sibsp: # of siblings / spouses aboard the Titanic\t\n",
    "# parch: # of parents / children aboard the Titanic\t\n",
    "# embarked (Port of Embarkation): C=Cherbourg, Q=Queenstown,S =Southampton\n",
    "\n",
    "print(all_data.shape)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c825a0",
   "metadata": {},
   "source": [
    "#### Male vs Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1059e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Sex'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eabdd1",
   "metadata": {},
   "source": [
    "#### Age Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db211fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Age'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c95a11",
   "metadata": {},
   "source": [
    "#### Average class price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.groupby('Pclass')['Fare'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d2d7b",
   "metadata": {},
   "source": [
    "## Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12fd76",
   "metadata": {},
   "source": [
    "#### Transform Male and Female into numberic. Female=0, Male=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f80ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Sex Numeric'] = train['Sex'].replace('female', 0).replace('male', 1)\n",
    "all_data['Sex'] = all_data['Sex'].map({'female': 0, 'male': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca94135",
   "metadata": {},
   "source": [
    "#### Impute Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cee11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for NaN\n",
    "\n",
    "# for c in all_data.columns:\n",
    "#     print(f\"column {c} has null values? {all_data[c].isnull().values.any()}\")\n",
    "\n",
    "age_na_count = len(all_data[all_data['Age'].isna()])\n",
    "all_count = len(all_data)\n",
    "\n",
    "print(f\"There are {age_na_count} na age records ({(age_na_count / all_count) * 100:.2f})%\")\n",
    "\n",
    "print(f\"Mean before: {all_data['Age'].mean()}\")\n",
    "\n",
    "# Mean Impute\n",
    "all_data['Age'] = all_data['Age'].fillna(all_data['Age'].mean())\n",
    "\n",
    "print(f\"After imputation There are {age_na_count} na age records ({(age_na_count / all_count) * 100:.2f})%\")\n",
    "print(f\"Mean after: {all_data['Age'].mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9762b8",
   "metadata": {},
   "source": [
    "## TEMP: DELETE NON NUMERIC COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f228c6",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f9222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df, size=11):\n",
    "    \"\"\"\n",
    "    Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n",
    "\n",
    "    Input:\n",
    "        df: pandas DataFrame\n",
    "        size: vertical and horizontal size of the plot\n",
    "\n",
    "    Displays:\n",
    "        matrix of correlation between columns.  Blue-cyan-yellow-red-darkred => less to more correlated\n",
    "                                                0 ------------------>  1\n",
    "                                                Expect a darkred line running from top left to bottom right\n",
    "    \"\"\"\n",
    "\n",
    "    corr = df.corr()    # data frame correlation function\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.matshow(corr)   # color code the rectangles by correlation value\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns)  # draw x tick marks\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)  # draw y tick marks\n",
    "\n",
    "plot_corr(all_data, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059593b1",
   "metadata": {},
   "source": [
    "## Split Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34468c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data[all_data.columns.difference(['Survived'])]\n",
    "y = all_data['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1c2f6",
   "metadata": {},
   "source": [
    "### Check Survival Distribution in Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "passengers_count = len(all_data)\n",
    "survived = len(all_data.loc[all_data['Survived'] == 1])\n",
    "drawn = len(all_data.loc[all_data['Survived'] == 0])\n",
    "print( f\"All data Survived passengers: {survived} ({(survived/passengers_count)*100:.2f}%)\")\n",
    "print( f\"All data Drawn passengers: {drawn} ({(drawn/passengers_count)*100:.2f}%)\")\n",
    "\n",
    "passengers_count = len(y_train)\n",
    "drawn, survived = y_train.value_counts()\n",
    "print( f\"Train data Survived passengers: {survived} ({(survived/passengers_count)*100:.2f}%)\")\n",
    "print( f\"Train data Drawn passengers: {drawn} ({(drawn/passengers_count)*100:.2f}%)\")\n",
    "\n",
    "passengers_count = len(y_test)\n",
    "drawn, survived = y_test.value_counts()\n",
    "print( f\"Test data Survived passengers: {survived} ({(survived/passengers_count)*100:.2f}%)\")\n",
    "print( f\"Test data Drawn passengers: {drawn} ({(drawn/passengers_count)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0b0fb",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "nb_model.fit(X_train, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c98c8a",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65488976",
   "metadata": {},
   "source": [
    "#### On Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176cb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# predict values using the training data\n",
    "nb_predict_train = nb_model.predict(X_train)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_train, nb_predict_train):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3369272b",
   "metadata": {},
   "source": [
    "#### On Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0305dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predict_test = nb_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test, nb_predict_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb9193",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "24f7fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7987\n",
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       374\n",
      "           1       0.76      0.67      0.71       222\n",
      "\n",
      "    accuracy                           0.80       596\n",
      "   macro avg       0.79      0.77      0.78       596\n",
      "weighted avg       0.80      0.80      0.80       596\n",
      "\n",
      "Test Accuracy: 0.8102\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       175\n",
      "           1       0.80      0.71      0.75       120\n",
      "\n",
      "    accuracy                           0.81       295\n",
      "   macro avg       0.81      0.79      0.80       295\n",
      "weighted avg       0.81      0.81      0.81       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(C=0.7, random_state=42, solver='liblinear', max_iter=10000)\n",
    "lr_model.fit(X_train, y_train.values)\n",
    "\n",
    "lr_predict_train = lr_model.predict(X_train)\n",
    "lr_predict_test = lr_model.predict(X_test)\n",
    "\n",
    "# training metrics\n",
    "print(\"Training Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_train, lr_predict_train)))\n",
    "print(\"Training Classification Report\")\n",
    "print(metrics.classification_report(y_train, lr_predict_train))\n",
    "# test metrics\n",
    "print(\"Test Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, lr_predict_test)))\n",
    "# print(metrics.confusion_matrix(y_test, lr_predict_test) )\n",
    "print(\"Test Classification Report\")\n",
    "print(metrics.classification_report(y_test, lr_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f96a4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
